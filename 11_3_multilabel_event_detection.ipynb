{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeakerDiarization\n",
      "VoiceActivityDetection\n",
      "OverlappedSpeechDetection\n",
      "MultiLabelSegmentation\n",
      "SpeakerEmbedding\n",
      "Segmentation\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio.tasks import __all__ as TASKS; print('\\n'.join(TASKS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'My_datasets_specified.SpeakerDiarization.Detection' found in /mnt/e/Files/Acoustic_Data/Datasets_specified/yaml/My_Databases_specified.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n"
     ]
    }
   ],
   "source": [
    "from pyannote.database import registry\n",
    "import os\n",
    "registry.load_database(\n",
    "    os.path.join('/mnt/', 'e', 'Files', 'Acoustic_Data', 'Datasets_specified', 'yaml','My_Databases_specified.yml')\n",
    "    )\n",
    "os.environ[\"PYANNOTE_DATABASE_CONFIG\"] = os.path.join('/mnt/', 'e', 'Files', 'Acoustic_Data', 'Datasets_specified','yaml', 'My_Databases_specified.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.database import get_protocol, FileFinder\n",
    "preprocessors = {\"audio\": FileFinder()}\n",
    "cow_audio = get_protocol('My_datasets_specified.SpeakerDiarization.Detection', \n",
    "                   preprocessors=preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuxiaohui9707/miniconda3/envs/myenv/lib/python3.8/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/home/wuxiaohui9707/miniconda3/envs/myenv/lib/python3.8/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol My_datasets_specified.SpeakerDiarization.Detection does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio.tasks import MultiLabelSegmentation\n",
    "task = MultiLabelSegmentation(protocol=cow_audio, \n",
    "    duration=1.0, \n",
    "    batch_size=32,\n",
    "    classes= [\"rumination\",\"hoofbeat\",\"breath\",\"gulp\",\"grazing\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySoundEventDetection(\n",
       "  (mfcc): MFCC(\n",
       "    (amplitude_to_DB): AmplitudeToDB()\n",
       "    (MelSpectrogram): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=40, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyannote.audio.models import custom_model\n",
    "model = custom_model.SoundEventDetection(task=task)\n",
    "\n",
    "#from pyannote.audio.models.segmentation import PyanNet\n",
    "#model = PyanNet(sincnet={'stride': 10}, task=task)\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params | In sizes      | Out sizes     \n",
      "----------------------------------------------------------------------------------------\n",
      "0 | mfcc              | MFCC             | 0      | [1, 1, 16000] | [1, 1, 40, 81]\n",
      "1 | linear1           | Linear           | 1.3 K  | [1, 81, 40]   | [1, 81, 32]   \n",
      "2 | linear2           | Linear           | 528    | [1, 81, 32]   | [1, 81, 16]   \n",
      "3 | classifier        | Linear           | 85     | [1, 81, 16]   | [1, 81, 5]    \n",
      "4 | activation        | Sigmoid          | 0      | [1, 81, 5]    | [1, 81, 5]    \n",
      "5 | validation_metric | MetricCollection | 0      | ?             | ?             \n",
      "----------------------------------------------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461d6c629792425496efe1126654c327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f3d85b034049f98d22933bf20d89da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6f11facf674550b1a55e2052642da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2751b61ef2444c08771f908ecfb2a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c028b104e32d47a792e82fe0d071584d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536bf833819543da9bb0133138c77b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbafc3d38a44c2a96db4fc406d8f2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b061463b738c4eafb9d8aa357b234b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b97c0c285945d7947a402cae52218d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c294766d044a4593c8f03ebf47f54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a434f0890484c3999984629d877814e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8a4046d6004c80ad27a66ee3a6d8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "output_directory = os.path.join('/mnt/', 'e', 'Files', 'Acoustic_Data', 'Datasets_specified')\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\", max_epochs=10, default_root_dir=output_directory)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:00:00.006 -->  00:00:00.030] A grazing\n",
      "[ 00:00:00.055 -->  00:00:00.228] B grazing\n",
      "[ 00:00:00.240 -->  00:00:00.759] C grazing\n",
      "[ 00:00:00.771 -->  00:00:00.845] D grazing\n",
      "[ 00:00:00.858 -->  00:00:01.043] E grazing\n",
      "[ 00:00:01.055 -->  00:00:01.067] F grazing\n",
      "[ 00:00:01.080 -->  00:00:01.191] G grazing\n",
      "[ 00:00:01.277 -->  00:00:01.635] H grazing\n",
      "[ 00:00:01.660 -->  00:00:01.771] I grazing\n",
      "[ 00:00:01.820 -->  00:00:02.450] J grazing\n",
      "[ 00:00:02.500 -->  00:00:04.611] K grazing\n",
      "[ 00:00:04.623 -->  00:00:04.858] L grazing\n",
      "[ 00:00:04.895 -->  00:00:04.956] M grazing\n",
      "[ 00:00:04.969 -->  00:00:05.006] N grazing\n",
      "[ 00:00:05.006 -->  00:00:05.018] A gulp\n",
      "[ 00:00:05.030 -->  00:00:05.524] O grazing\n",
      "[ 00:00:05.561 -->  00:00:05.672] P grazing\n",
      "[ 00:00:05.685 -->  00:00:05.746] Q grazing\n",
      "[ 00:00:05.771 -->  00:00:05.796] R grazing\n",
      "[ 00:00:05.845 -->  00:00:05.858] S grazing\n",
      "[ 00:00:05.882 -->  00:00:05.907] T grazing\n",
      "[ 00:00:05.919 -->  00:00:05.932] U grazing\n",
      "[ 00:00:05.944 -->  00:00:06.401] V grazing\n",
      "[ 00:00:06.512 -->  00:00:06.549] W grazing\n",
      "[ 00:00:06.574 -->  00:00:06.709] X grazing\n",
      "[ 00:00:06.709 -->  00:00:06.722] B gulp\n",
      "[ 00:00:06.722 -->  00:00:06.771] Y grazing\n",
      "[ 00:00:06.808 -->  00:00:06.932] Z grazing\n",
      "[ 00:00:06.944 -->  00:00:07.166] AA grazing\n",
      "[ 00:00:07.191 -->  00:00:07.216] AB grazing\n",
      "[ 00:00:07.228 -->  00:00:07.364] AC grazing\n",
      "[ 00:00:07.438 -->  00:00:08.018] AD grazing\n",
      "[ 00:00:08.030 -->  00:00:08.092] AE grazing\n",
      "[ 00:00:08.117 -->  00:00:08.574] AF grazing\n",
      "[ 00:00:08.648 -->  00:00:08.660] AG grazing\n",
      "[ 00:00:08.672 -->  00:00:08.685] C gulp\n",
      "[ 00:00:08.709 -->  00:00:09.401] AH grazing\n",
      "[ 00:00:09.549 -->  00:00:09.586] AI grazing\n",
      "[ 00:00:09.598 -->  00:00:09.820] AJ grazing\n",
      "[ 00:00:09.845 -->  00:00:09.858] D gulp\n",
      "[ 00:00:09.858 -->  00:00:09.895] AK grazing\n",
      "[ 00:00:09.907 -->  00:00:09.993] AL grazing\n",
      "[ 00:00:10.018 -->  00:00:10.141] AM grazing\n",
      "[ 00:00:10.166 -->  00:00:10.179] AN grazing\n",
      "[ 00:00:10.203 -->  00:00:10.240] AO grazing\n",
      "[ 00:00:10.253 -->  00:00:10.277] AP grazing\n",
      "[ 00:00:10.290 -->  00:00:10.697] AQ grazing\n",
      "[ 00:00:10.746 -->  00:00:10.771] AR grazing\n",
      "[ 00:00:10.783 -->  00:00:10.981] AS grazing\n",
      "[ 00:00:11.006 -->  00:00:11.820] AT grazing\n",
      "[ 00:00:11.845 -->  00:00:12.018] AU grazing\n",
      "[ 00:00:12.030 -->  00:00:12.166] AV grazing\n",
      "[ 00:00:12.203 -->  00:00:12.228] AW grazing\n",
      "[ 00:00:12.302 -->  00:00:12.314] AX grazing\n",
      "[ 00:00:12.388 -->  00:00:12.413] AY grazing\n",
      "[ 00:00:12.450 -->  00:00:12.635] AZ grazing\n",
      "[ 00:00:12.660 -->  00:00:13.759] BA grazing\n",
      "[ 00:00:13.783 -->  00:00:14.870] BB grazing\n",
      "[ 00:00:14.895 -->  00:00:14.919] BC grazing\n",
      "[ 00:00:14.932 -->  00:00:14.993] BD grazing\n",
      "[ 00:00:15.018 -->  00:00:15.141] BE grazing\n",
      "[ 00:00:15.203 -->  00:00:15.240] BF grazing\n",
      "[ 00:00:15.314 -->  00:00:15.327] BG grazing\n",
      "[ 00:00:15.425 -->  00:00:15.635] BH grazing\n",
      "[ 00:00:15.746 -->  00:00:16.907] BI grazing\n",
      "[ 00:00:16.932 -->  00:00:16.956] BJ grazing\n",
      "[ 00:00:16.969 -->  00:00:17.302] BK grazing\n",
      "[ 00:00:17.401 -->  00:00:17.820] BL grazing\n",
      "[ 00:00:17.833 -->  00:00:17.845] BM grazing\n",
      "[ 00:00:17.858 -->  00:00:18.092] BN grazing\n",
      "[ 00:00:18.141 -->  00:00:18.660] BO grazing\n",
      "[ 00:00:18.685 -->  00:00:18.722] BP grazing\n",
      "[ 00:00:18.808 -->  00:00:19.808] BQ grazing\n",
      "[ 00:00:19.858 -->  00:00:20.141] BR grazing\n",
      "[ 00:00:20.166 -->  00:00:20.228] BS grazing\n",
      "[ 00:00:20.302 -->  00:00:20.734] BT grazing\n",
      "[ 00:00:20.746 -->  00:00:20.771] BU grazing\n",
      "[ 00:00:20.808 -->  00:00:20.895] BV grazing\n",
      "[ 00:00:20.907 -->  00:00:21.635] BW grazing\n",
      "[ 00:00:21.660 -->  00:00:21.734] BX grazing\n",
      "[ 00:00:21.771 -->  00:00:21.858] BY grazing\n",
      "[ 00:00:21.870 -->  00:00:22.055] BZ grazing\n",
      "[ 00:00:22.067 -->  00:00:22.166] CA grazing\n",
      "[ 00:00:22.179 -->  00:00:22.191] CB grazing\n",
      "[ 00:00:22.228 -->  00:00:22.808] CC grazing\n",
      "[ 00:00:22.919 -->  00:00:24.265] CD grazing\n",
      "[ 00:00:24.388 -->  00:00:24.401] CE grazing\n",
      "[ 00:00:24.487 -->  00:00:24.574] CF grazing\n",
      "[ 00:00:24.611 -->  00:00:24.783] CG grazing\n",
      "[ 00:00:24.796 -->  00:00:25.055] CH grazing\n",
      "[ 00:00:25.067 -->  00:00:25.685] CI grazing\n",
      "[ 00:00:25.697 -->  00:00:25.759] CJ grazing\n",
      "[ 00:00:25.796 -->  00:00:25.907] CK grazing\n",
      "[ 00:00:25.944 -->  00:00:26.067] CL grazing\n",
      "[ 00:00:26.092 -->  00:00:26.290] CM grazing\n",
      "[ 00:00:26.376 -->  00:00:27.364] CN grazing\n",
      "[ 00:00:27.376 -->  00:00:27.820] CO grazing\n",
      "[ 00:00:27.833 -->  00:00:27.870] CP grazing\n",
      "[ 00:00:27.882 -->  00:00:28.104] CQ grazing\n",
      "[ 00:00:28.117 -->  00:00:28.166] CR grazing\n",
      "[ 00:00:28.179 -->  00:00:28.895] CS grazing\n",
      "[ 00:00:28.932 -->  00:00:29.771] CT grazing\n",
      "[ 00:00:29.783 -->  00:00:29.981] CU grazing\n",
      "[ 00:00:29.993 -->  00:00:30.080] CV grazing\n",
      "[ 00:00:30.104 -->  00:00:30.191] CW grazing\n",
      "[ 00:00:30.216 -->  00:00:30.450] CX grazing\n",
      "[ 00:00:30.475 -->  00:00:30.759] CY grazing\n",
      "[ 00:00:30.796 -->  00:00:30.907] CZ grazing\n",
      "[ 00:00:30.919 -->  00:00:30.944] DA grazing\n",
      "[ 00:00:30.969 -->  00:00:30.993] DB grazing\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio.pipelines import MultiLabelSegmentation\n",
    "test_file = next(cow_audio.test())\n",
    "pipeline = MultiLabelSegmentation(segmentation=model)\n",
    "initial_params = {\n",
    "    \"thresholds\": {\n",
    "        \"rumination\": {\"onset\": 0.8, \"offset\": 0.6, \"min_duration_on\": 0.01, \"min_duration_off\": 0.00},\n",
    "        \"breath\": {\"onset\": 0.8, \"offset\": 0.6, \"min_duration_on\": 0.01, \"min_duration_off\": 0.01},\n",
    "        \"hoofbeat\": {\"onset\": 0.8, \"offset\": 0.6, \"min_duration_on\": 0.005, \"min_duration_off\": 0.005},\n",
    "        \"grazing\": {\"onset\": 0.8, \"offset\": 0.6, \"min_duration_on\": 0.005, \"min_duration_off\": 0.005},\n",
    "        \"gulp\": {\"onset\": 0.8, \"offset\": 0.6, \"min_duration_on\": 0.005, \"min_duration_off\": 0.005},\n",
    "    }\n",
    "}\n",
    "pipeline.instantiate(initial_params)\n",
    "detection = pipeline(test_file)\n",
    "print(detection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
